{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-12-06T21:15:49.761950Z",
     "iopub.status.busy": "2023-12-06T21:15:49.761950Z",
     "iopub.status.idle": "2023-12-06T21:15:52.881715Z",
     "shell.execute_reply": "2023-12-06T21:15:52.881715Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import absl.logging\n",
    "import PIL.Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Callable\n",
    "from tensorflow import keras\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..', '..', '..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(os.path.join(module_path))\n",
    "\n",
    "from functions.ciou import ciou_loss, ciou_metric\n",
    "from functions.loading_data import SMALLER_HEIGHT, SMALLER_WIDTH\n",
    "from functions.model_running import get_run_number, finalize_run\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-12-06T21:15:52.881715Z",
     "iopub.status.busy": "2023-12-06T21:15:52.881715Z",
     "iopub.status.idle": "2023-12-06T21:15:52.897368Z",
     "shell.execute_reply": "2023-12-06T21:15:52.897368Z"
    }
   },
   "outputs": [],
   "source": [
    "get_names = lambda root_path: [\n",
    "    file_name.split('.')[0]\n",
    "    for dir_path, _, file_names in os.walk(root_path)\n",
    "    for file_name in file_names\n",
    "]\n",
    "get_paths = lambda path: [f'{os.path.join(root, file)}' for root, dirs, files in os.walk(path) for file in files]\n",
    "base_dir = os.path.join('..', '..', '..', '..', '..', 'data1', 'images_original_inception_resnet_v2_200x150_splitted')\n",
    "train_dir = os.path.join(base_dir, 'training')\n",
    "valid_dir = os.path.join(base_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-12-06T21:15:52.897368Z",
     "iopub.status.busy": "2023-12-06T21:15:52.897368Z",
     "iopub.status.idle": "2023-12-06T21:16:10.585565Z",
     "shell.execute_reply": "2023-12-06T21:16:10.585565Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_images_array(paths: list[str]) -> np.ndarray:\n",
    "    rows = []\n",
    "    rescale = keras.layers.Rescaling(1./255)\n",
    "\n",
    "    for path in paths:\n",
    "        with PIL.Image.open(path) as image:\n",
    "            image_array = np.asarray(image)\n",
    "            rescaled_image = rescale(image_array)\n",
    "            rows.append(rescaled_image)\n",
    "\n",
    "    return np.array(rows)\n",
    "\n",
    "\n",
    "train_paths = get_paths(train_dir)\n",
    "valid_paths = get_paths(valid_dir)\n",
    "X_train = get_images_array(train_paths)\n",
    "X_valid = get_images_array(valid_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-12-06T21:16:10.585565Z",
     "iopub.status.busy": "2023-12-06T21:16:10.585565Z",
     "iopub.status.idle": "2023-12-06T21:16:10.632443Z",
     "shell.execute_reply": "2023-12-06T21:16:10.632443Z"
    }
   },
   "outputs": [],
   "source": [
    "train_names = set(get_names(train_dir))\n",
    "valid_names = set(get_names(valid_dir))\n",
    "metadata_path = os.path.join('..', '..', '..', '..', '..', 'data1', 'HAM10000_metadata_ext.csv')\n",
    "data = pd.read_csv(metadata_path).sort_values(by='image_id')\n",
    "relevant_cols = ['top', 'left', 'bottom', 'right']\n",
    "train_df = data[data['image_id'].isin(train_names)][relevant_cols]\n",
    "valid_df = data[data['image_id'].isin(valid_names)][relevant_cols]\n",
    "ys_train = train_df.to_numpy().astype(float)\n",
    "ys_train[:, [0, 2]] /= SMALLER_HEIGHT\n",
    "ys_train[:, [1, 3]] /= SMALLER_WIDTH\n",
    "ys_valid = valid_df.to_numpy().astype(float)\n",
    "ys_valid[:, [0, 2]] /= SMALLER_HEIGHT\n",
    "ys_valid[:, [1, 3]] /= SMALLER_WIDTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-12-06T21:16:10.632443Z",
     "iopub.status.busy": "2023-12-06T21:16:10.632443Z",
     "iopub.status.idle": "2023-12-06T21:16:10.648487Z",
     "shell.execute_reply": "2023-12-06T21:16:10.648487Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_attentive_model(loss: Callable, metric: Callable) -> keras.Model:\n",
    "    def get_branch(_input: keras.layers.Layer, kernel_size: int) -> keras.layers.Layer:\n",
    "        conv = keras.layers.Conv2D(128, kernel_size, padding='same', strides=2, activation='relu')(_input)\n",
    "        conv = keras.layers.MaxPooling2D()(conv)\n",
    "\n",
    "        return conv\n",
    "\n",
    "    def get_inner_conv_module(prev: keras.layers.Layer, filters: int) -> keras.layers.Layer:\n",
    "        conv_module = keras.layers.Conv2D(filters, 3, padding='same', activation='relu')(prev)\n",
    "        conv_module = keras.layers.MaxPooling2D()(conv_module)\n",
    "        conv_module = keras.layers.Dropout(.4)(conv_module)\n",
    "\n",
    "        return conv_module\n",
    "\n",
    "    def get_outer_conv_module(prev: keras.layers.Layer) -> keras.layers.Layer:\n",
    "        conv_module = get_inner_conv_module(prev, 64)\n",
    "        conv_module = get_inner_conv_module(conv_module, 128)\n",
    "        conv_module = get_inner_conv_module(conv_module, 256)\n",
    "\n",
    "        return conv_module\n",
    "\n",
    "    def get_attention_module(prev: keras.layers.Layer, num: int) -> keras.layers.Layer:\n",
    "        gap_layer = keras.layers.GlobalAveragePooling2D(name=f'attention_gap_{num}')(prev)\n",
    "        gap_layer_res = keras.layers.Reshape((1, 1, 256))(gap_layer)\n",
    "        dense = keras.layers.Dense(256, activation='relu')(gap_layer_res)\n",
    "        dense = keras.layers.Dense(256, activation='softmax')(dense)\n",
    "        mul_layer = keras.layers.Multiply()([prev, dense])\n",
    "\n",
    "        return mul_layer\n",
    "\n",
    "    def get_locator_module(prev: keras.layers.Layer) -> keras.layers.Layer:\n",
    "        locator_module = keras.layers.Flatten()(prev)\n",
    "        locator_module = keras.layers.Dense(256, activation='relu')(locator_module)\n",
    "        locator_module = keras.layers.Dense(128, activation='relu')(locator_module)\n",
    "\n",
    "        return locator_module\n",
    "\n",
    "    _input = keras.layers.Input(shape=(SMALLER_HEIGHT, SMALLER_WIDTH, 3))\n",
    "    branch1 = get_branch(_input, 3)\n",
    "    branch2 = get_branch(_input, 5)\n",
    "    branch3 = get_branch(_input, 7)\n",
    "    merged_branches = keras.layers.concatenate([branch1, branch2, branch3])\n",
    "    conv_module = get_outer_conv_module(merged_branches)\n",
    "    attention_module1 = get_attention_module(conv_module, 1)\n",
    "    attention_module2 = get_attention_module(conv_module, 2)\n",
    "    merged_attentions = keras.layers.concatenate([attention_module1, attention_module2])\n",
    "    locator_module = get_locator_module(merged_attentions)\n",
    "    output = keras.layers.Dense(4, activation='sigmoid', name='root')(locator_module)\n",
    "    gap_attention1 = keras.layers.GlobalAveragePooling2D()(attention_module1)\n",
    "    gap_attention2 = keras.layers.GlobalAveragePooling2D()(attention_module2)\n",
    "    aux_output = keras.layers.Dot(axes=1, normalize=True, name='dot')([gap_attention1, gap_attention2])\n",
    "    model = keras.Model(_input, outputs=[output, aux_output])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'root': loss,\n",
    "            'dot': keras.losses.mean_squared_error,\n",
    "        },\n",
    "        loss_weights={'root': 1.0, 'dot': 0.1},\n",
    "        metrics={\n",
    "            'root': metric,\n",
    "            'dot': keras.metrics.mean_squared_error\n",
    "        })\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-12-06T21:16:10.648487Z",
     "iopub.status.busy": "2023-12-06T21:16:10.648487Z",
     "iopub.status.idle": "2023-12-06T21:16:10.664150Z",
     "shell.execute_reply": "2023-12-06T21:16:10.664150Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_multi_attentive_model(\n",
    "        model_factory: Callable,\n",
    "        model_name: str,\n",
    "        loss: Callable,\n",
    "        metric: Callable,\n",
    "        reduction_patience=5,\n",
    "        monitor='val_root_ciou_metric'):\n",
    "    MIN_DELTA = .001\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=monitor,\n",
    "        mode='max',\n",
    "        patience=20,\n",
    "        min_delta=MIN_DELTA)\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=monitor,\n",
    "        mode='max',\n",
    "        factor=0.95,\n",
    "        min_delta=MIN_DELTA,\n",
    "        patience=reduction_patience,\n",
    "        min_lr=0.0005,\n",
    "        verbose=1)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join('..', '..', '..', '..', 'tmp_models', model_name + '_{epoch}'),\n",
    "        save_best_only=True)\n",
    "    tensor_board = keras.callbacks.TensorBoard(log_dir=os.path.join('..', '..', '..', '..', 'tensor_logs', model_name))\n",
    "    model = model_factory(loss, metric)\n",
    "\n",
    "    return model.fit(\n",
    "        X_train,\n",
    "        {'root': ys_train, 'dot': np.zeros((len(ys_train,),))},\n",
    "        validation_data=(X_valid, {'root': ys_valid, 'dot': np.zeros((len(ys_valid,),))}),\n",
    "        epochs=500,\n",
    "        batch_size=64,\n",
    "        callbacks=[reduce_lr, model_checkpoint, tensor_board, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-12-06T21:16:10.664150Z",
     "iopub.status.busy": "2023-12-06T21:16:10.664150Z",
     "iopub.status.idle": "2023-12-06T21:22:31.821348Z",
     "shell.execute_reply": "2023-12-06T21:22:31.821348Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 150, 200, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 75, 100, 128  3584        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 75, 100, 128  9728        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 75, 100, 128  18944       ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 37, 50, 128)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 37, 50, 128)  0          ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 37, 50, 128)  0          ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 37, 50, 384)  0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'max_pooling2d_1[0][0]',        \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 37, 50, 64)   221248      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 18, 25, 64)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 18, 25, 64)   0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 18, 25, 128)  73856       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 9, 12, 128)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 9, 12, 128)   0           ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 9, 12, 256)   295168      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 4, 6, 256)   0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4, 6, 256)    0           ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " attention_gap_1 (GlobalAverage  (None, 256)         0           ['dropout_2[0][0]']              \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " attention_gap_2 (GlobalAverage  (None, 256)         0           ['dropout_2[0][0]']              \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1, 256)    0           ['attention_gap_1[0][0]']        \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 1, 256)    0           ['attention_gap_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 1, 256)    65792       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1, 1, 256)    65792       ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1, 256)    65792       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1, 1, 256)    65792       ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 4, 6, 256)    0           ['dropout_2[0][0]',              \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 4, 6, 256)    0           ['dropout_2[0][0]',              \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 4, 6, 512)    0           ['multiply[0][0]',               \n",
      "                                                                  'multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 12288)        0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          3145984     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          32896       ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 256)         0           ['multiply[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 256)         0           ['multiply_1[0][0]']             \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " root (Dense)                   (None, 4)            516         ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1)            0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 , 'global_average_pooling2d_1[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,065,092\n",
      "Trainable params: 4,065,092\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.5330 - root_loss: 0.5322 - dot_loss: 0.0087 - root_ciou_metric: 0.4674 - dot_mean_squared_error: 0.0087INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 26s 154ms/step - loss: 0.5330 - root_loss: 0.5322 - dot_loss: 0.0087 - root_ciou_metric: 0.4674 - dot_mean_squared_error: 0.0087 - val_loss: 0.5104 - val_root_loss: 0.5104 - val_dot_loss: 2.0053e-17 - val_root_ciou_metric: 0.4894 - val_dot_mean_squared_error: 2.0053e-17 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "126/126 [==============================] - 15s 116ms/step - loss: 0.5048 - root_loss: 0.5048 - dot_loss: 6.2099e-21 - root_ciou_metric: 0.4956 - dot_mean_squared_error: 6.2099e-21 - val_loss: 0.5278 - val_root_loss: 0.5278 - val_dot_loss: 8.8223e-13 - val_root_ciou_metric: 0.4720 - val_dot_mean_squared_error: 8.8223e-13 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "126/126 [==============================] - 14s 115ms/step - loss: 0.5000 - root_loss: 0.5000 - dot_loss: 1.2545e-16 - root_ciou_metric: 0.5004 - dot_mean_squared_error: 1.2545e-16 - val_loss: 0.5475 - val_root_loss: 0.5475 - val_dot_loss: 6.9213e-09 - val_root_ciou_metric: 0.4526 - val_dot_mean_squared_error: 6.9213e-09 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.4952 - root_loss: 0.4952 - dot_loss: 3.9065e-11 - root_ciou_metric: 0.5048 - dot_mean_squared_error: 3.9065e-11INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 17s 135ms/step - loss: 0.4952 - root_loss: 0.4952 - dot_loss: 3.8996e-11 - root_ciou_metric: 0.5048 - dot_mean_squared_error: 3.8996e-11 - val_loss: 0.5039 - val_root_loss: 0.5039 - val_dot_loss: 6.4809e-06 - val_root_ciou_metric: 0.4961 - val_dot_mean_squared_error: 6.4809e-06 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.4923 - root_loss: 0.4923 - dot_loss: 6.1692e-11 - root_ciou_metric: 0.5077 - dot_mean_squared_error: 6.1692e-11INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 17s 134ms/step - loss: 0.4922 - root_loss: 0.4922 - dot_loss: 6.1578e-11 - root_ciou_metric: 0.5080 - dot_mean_squared_error: 6.1578e-11 - val_loss: 0.4950 - val_root_loss: 0.4950 - val_dot_loss: 1.3748e-04 - val_root_ciou_metric: 0.5047 - val_dot_mean_squared_error: 1.3748e-04 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "126/126 [==============================] - 14s 112ms/step - loss: 0.4912 - root_loss: 0.4912 - dot_loss: 8.5948e-08 - root_ciou_metric: 0.5086 - dot_mean_squared_error: 8.5948e-08 - val_loss: 0.4953 - val_root_loss: 0.4952 - val_dot_loss: 0.0012 - val_root_ciou_metric: 0.5045 - val_dot_mean_squared_error: 0.0012 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "126/126 [==============================] - 14s 111ms/step - loss: 0.4908 - root_loss: 0.4908 - dot_loss: 3.8524e-09 - root_ciou_metric: 0.5087 - dot_mean_squared_error: 3.8524e-09 - val_loss: 0.4960 - val_root_loss: 0.4959 - val_dot_loss: 4.4928e-04 - val_root_ciou_metric: 0.5038 - val_dot_mean_squared_error: 4.4928e-04 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.4910 - root_loss: 0.4910 - dot_loss: 4.7738e-08 - root_ciou_metric: 0.5090 - dot_mean_squared_error: 4.7738e-08INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 17s 133ms/step - loss: 0.4911 - root_loss: 0.4911 - dot_loss: 4.8118e-08 - root_ciou_metric: 0.5089 - dot_mean_squared_error: 4.8118e-08 - val_loss: 0.4950 - val_root_loss: 0.4948 - val_dot_loss: 0.0012 - val_root_ciou_metric: 0.5050 - val_dot_mean_squared_error: 0.0012 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "126/126 [==============================] - 14s 111ms/step - loss: 0.4908 - root_loss: 0.4908 - dot_loss: 5.0228e-09 - root_ciou_metric: 0.5098 - dot_mean_squared_error: 5.0228e-09 - val_loss: 0.4951 - val_root_loss: 0.4951 - val_dot_loss: 3.3020e-04 - val_root_ciou_metric: 0.5047 - val_dot_mean_squared_error: 3.3020e-04 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.4910 - root_loss: 0.4910 - dot_loss: 1.0477e-07 - root_ciou_metric: 0.5090 - dot_mean_squared_error: 1.0477e-07\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "126/126 [==============================] - 14s 111ms/step - loss: 0.4909 - root_loss: 0.4909 - dot_loss: 1.0498e-07 - root_ciou_metric: 0.5097 - dot_mean_squared_error: 1.0498e-07 - val_loss: 0.4953 - val_root_loss: 0.4950 - val_dot_loss: 0.0027 - val_root_ciou_metric: 0.5047 - val_dot_mean_squared_error: 0.0027 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "126/126 [==============================] - 14s 111ms/step - loss: 0.4907 - root_loss: 0.4907 - dot_loss: 8.9125e-08 - root_ciou_metric: 0.5090 - dot_mean_squared_error: 8.9125e-08 - val_loss: 0.4951 - val_root_loss: 0.4951 - val_dot_loss: 1.3178e-04 - val_root_ciou_metric: 0.5046 - val_dot_mean_squared_error: 1.3178e-04 - lr: 9.5000e-04\n",
      "Epoch 12/500\n",
      "126/126 [==============================] - 14s 110ms/step - loss: 0.4911 - root_loss: 0.4911 - dot_loss: 2.7734e-06 - root_ciou_metric: 0.5093 - dot_mean_squared_error: 2.7734e-06 - val_loss: 0.4959 - val_root_loss: 0.4951 - val_dot_loss: 0.0079 - val_root_ciou_metric: 0.5047 - val_dot_mean_squared_error: 0.0079 - lr: 9.5000e-04\n",
      "Epoch 13/500\n",
      "126/126 [==============================] - 14s 111ms/step - loss: 0.4911 - root_loss: 0.4911 - dot_loss: 4.1960e-06 - root_ciou_metric: 0.5088 - dot_mean_squared_error: 4.1960e-06 - val_loss: 0.4954 - val_root_loss: 0.4950 - val_dot_loss: 0.0033 - val_root_ciou_metric: 0.5047 - val_dot_mean_squared_error: 0.0033 - lr: 9.5000e-04\n",
      "Epoch 14/500\n",
      "126/126 [==============================] - 14s 110ms/step - loss: 0.4908 - root_loss: 0.4908 - dot_loss: 4.6847e-07 - root_ciou_metric: 0.5082 - dot_mean_squared_error: 4.6847e-07 - val_loss: 0.4955 - val_root_loss: 0.4954 - val_dot_loss: 9.4983e-04 - val_root_ciou_metric: 0.5044 - val_dot_mean_squared_error: 9.4983e-04 - lr: 9.5000e-04\n",
      "Epoch 15/500\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.4913 - root_loss: 0.4913 - dot_loss: 3.5687e-07 - root_ciou_metric: 0.5087 - dot_mean_squared_error: 3.5687e-07\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "126/126 [==============================] - 14s 111ms/step - loss: 0.4913 - root_loss: 0.4913 - dot_loss: 3.5639e-07 - root_ciou_metric: 0.5089 - dot_mean_squared_error: 3.5639e-07 - val_loss: 0.4953 - val_root_loss: 0.4950 - val_dot_loss: 0.0021 - val_root_ciou_metric: 0.5047 - val_dot_mean_squared_error: 0.0021 - lr: 9.5000e-04\n",
      "Epoch 16/500\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.4909 - root_loss: 0.4909 - dot_loss: 4.6343e-05 - root_ciou_metric: 0.5091 - dot_mean_squared_error: 4.6343e-05INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_16\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_16\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 17s 132ms/step - loss: 0.4908 - root_loss: 0.4908 - dot_loss: 4.6256e-05 - root_ciou_metric: 0.5096 - dot_mean_squared_error: 4.6256e-05 - val_loss: 0.4949 - val_root_loss: 0.4949 - val_dot_loss: 0.0000e+00 - val_root_ciou_metric: 0.5049 - val_dot_mean_squared_error: 0.0000e+00 - lr: 9.0250e-04\n",
      "Epoch 17/500\n",
      "126/126 [==============================] - 14s 111ms/step - loss: 0.4907 - root_loss: 0.4907 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5099 - dot_mean_squared_error: 0.0000e+00 - val_loss: 0.4956 - val_root_loss: 0.4956 - val_dot_loss: 0.0000e+00 - val_root_ciou_metric: 0.5040 - val_dot_mean_squared_error: 0.0000e+00 - lr: 9.0250e-04\n",
      "Epoch 18/500\n",
      "126/126 [==============================] - 14s 110ms/step - loss: 0.4909 - root_loss: 0.4909 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5096 - dot_mean_squared_error: 0.0000e+00 - val_loss: 0.4950 - val_root_loss: 0.4950 - val_dot_loss: 0.0000e+00 - val_root_ciou_metric: 0.5047 - val_dot_mean_squared_error: 0.0000e+00 - lr: 9.0250e-04\n",
      "Epoch 19/500\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.4909 - root_loss: 0.4909 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5091 - dot_mean_squared_error: 0.0000e+00INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_19\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_19\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 17s 132ms/step - loss: 0.4908 - root_loss: 0.4908 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5098 - dot_mean_squared_error: 0.0000e+00 - val_loss: 0.4947 - val_root_loss: 0.4947 - val_dot_loss: 0.0000e+00 - val_root_ciou_metric: 0.5051 - val_dot_mean_squared_error: 0.0000e+00 - lr: 9.0250e-04\n",
      "Epoch 20/500\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.4908 - root_loss: 0.4908 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5092 - dot_mean_squared_error: 0.0000e+00\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "126/126 [==============================] - 14s 110ms/step - loss: 0.4907 - root_loss: 0.4907 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5096 - dot_mean_squared_error: 0.0000e+00 - val_loss: 0.4955 - val_root_loss: 0.4955 - val_dot_loss: 0.0000e+00 - val_root_ciou_metric: 0.5041 - val_dot_mean_squared_error: 0.0000e+00 - lr: 9.0250e-04\n",
      "Epoch 21/500\n",
      "126/126 [==============================] - 14s 110ms/step - loss: 0.4908 - root_loss: 0.4908 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5095 - dot_mean_squared_error: 0.0000e+00 - val_loss: 0.4948 - val_root_loss: 0.4948 - val_dot_loss: 0.0000e+00 - val_root_ciou_metric: 0.5050 - val_dot_mean_squared_error: 0.0000e+00 - lr: 8.5737e-04\n",
      "Epoch 22/500\n",
      "126/126 [==============================] - 14s 110ms/step - loss: 0.4907 - root_loss: 0.4907 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5100 - dot_mean_squared_error: 0.0000e+00 - val_loss: 0.4949 - val_root_loss: 0.4949 - val_dot_loss: 0.0000e+00 - val_root_ciou_metric: 0.5048 - val_dot_mean_squared_error: 0.0000e+00 - lr: 8.5737e-04\n",
      "Epoch 23/500\n",
      "126/126 [==============================] - 14s 110ms/step - loss: 0.4909 - root_loss: 0.4909 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5084 - dot_mean_squared_error: 0.0000e+00 - val_loss: 0.4948 - val_root_loss: 0.4948 - val_dot_loss: 0.0000e+00 - val_root_ciou_metric: 0.5049 - val_dot_mean_squared_error: 0.0000e+00 - lr: 8.5737e-04\n",
      "Epoch 24/500\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.4909 - root_loss: 0.4909 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5091 - dot_mean_squared_error: 0.0000e+00INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_24\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ..\\..\\..\\..\\tmp_models\\custom_models_7_multiattentive_model_20_24\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 16s 131ms/step - loss: 0.4909 - root_loss: 0.4909 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5093 - dot_mean_squared_error: 0.0000e+00 - val_loss: 0.4946 - val_root_loss: 0.4946 - val_dot_loss: 0.0000e+00 - val_root_ciou_metric: 0.5052 - val_dot_mean_squared_error: 0.0000e+00 - lr: 8.5737e-04\n",
      "Epoch 25/500\n",
      "125/126 [============================>.] - ETA: 0s - loss: 0.4907 - root_loss: 0.4907 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5093 - dot_mean_squared_error: 0.0000e+00\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "126/126 [==============================] - 14s 110ms/step - loss: 0.4908 - root_loss: 0.4908 - dot_loss: 0.0000e+00 - root_ciou_metric: 0.5089 - dot_mean_squared_error: 0.0000e+00 - val_loss: 0.4947 - val_root_loss: 0.4947 - val_dot_loss: 0.0000e+00 - val_root_ciou_metric: 0.5051 - val_dot_mean_squared_error: 0.0000e+00 - lr: 8.5737e-04\n"
     ]
    }
   ],
   "source": [
    "model_base_name = 'custom_models_7_multiattentive_model'\n",
    "run_number = get_run_number(model_base_name)\n",
    "model_name = f'{model_base_name}_{run_number}'\n",
    "history = run_multi_attentive_model(get_attentive_model, model_name, ciou_loss, ciou_metric)\n",
    "ROOT = os.path.join('..', '..', '..', '..')\n",
    "DS_NAME = 'data1_roi'\n",
    "plot_name = f'{model_name}.pdf'\n",
    "\n",
    "finalize_run(ROOT, plot_name, model_base_name, DS_NAME, history, plot_mode = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
