{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(os.path.join(module_path))\n",
    "\n",
    "from tensorflow import keras\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "from functions.plotting import plot_bars, plot_bar_from_dict\n",
    "\n",
    "WIDTH = 150\n",
    "HEIGHT = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(\n",
    "    '..',\n",
    "    '..',\n",
    "    '..',\n",
    "    'data1',\n",
    "    'images_original_inception_resnet_v2_150x150_categorized')\n",
    "test_data_dir = os.path.join(data_dir, 'validation')\n",
    "test_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=test_data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(HEIGHT, WIDTH))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "models_dir = os.path.join(\n",
    "    '..',\n",
    "    '..',\n",
    "    'models',\n",
    "    'data1')\n",
    "model_names = os.listdir(models_dir)\n",
    "non_normalized_models = \\\n",
    "    list(\n",
    "        filter(\n",
    "            lambda model_file_name: not 'normalization' in model_file_name,\n",
    "            model_names))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_accuracies_and_losses(models: list[str]) -> (dict[str, float], dict[str, float]):\n",
    "    accuracies = {}\n",
    "    losses = {}\n",
    "\n",
    "    for model_name in models:\n",
    "        model_path = os.path.join(models_dir, model_name)\n",
    "        model = keras.models.load_model(model_path)\n",
    "        loss, accuracy = model.evaluate(test_ds)\n",
    "        accuracies[model_name] = accuracy\n",
    "        losses[model_name] = loss\n",
    "\n",
    "    return accuracies, losses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "accuracies_wo_norm_data_path = os.path.join('..', '..', 'histories', 'accuracies_wo_norm.json')\n",
    "losses_wo_norm_data_path = os.path.join('..', '..', 'histories', 'losses_wo_norm.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "if not os.path.exists(accuracies_wo_norm_data_path):\n",
    "    accuracies_wo_norm, losses_wo_norm = get_accuracies_and_losses(non_normalized_models)\n",
    "\n",
    "    with open(accuracies_wo_norm_data_path, 'w') as json_file:\n",
    "        json.dump(accuracies_wo_norm, json_file, indent=4)\n",
    "    with open(losses_wo_norm_data_path, 'w') as json_file:\n",
    "        json.dump(losses_wo_norm, json_file, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "with open(accuracies_wo_norm_data_path, 'r') as losses_file:\n",
    "    accuracies_wo_norm = json.load(losses_file)\n",
    "with open(losses_wo_norm_data_path, 'r') as losses_file:\n",
    "    losses_wo_norm = json.load(losses_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "root = os.path.join('..', '..', 'plots', 'testing')\n",
    "accuracies_path = os.path.join(root, 'accuracies.pdf')\n",
    "\n",
    "plot_bar_from_dict(accuracies_wo_norm, 'Model Accuracies', 'Name', 'Accuracy', accuracies_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses_path = os.path.join(root, 'losses.pdf')\n",
    "\n",
    "plot_bar_from_dict(losses_wo_norm, 'Model Losses', 'Name', 'Accuracy', losses_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "normalized_models = \\\n",
    "    list(\n",
    "    filter(\n",
    "        lambda model_file_name: 'normalization' in model_file_name,\n",
    "        model_names))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracies_w_norm, losses_w_norm = get_accuracies_and_losses(normalized_models)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "accuracies_norm_data_path = os.path.join('..', '..', 'histories', 'accuracies_norm.json')\n",
    "losses_norm_data_path = os.path.join('..', '..', 'histories', 'losses_norm.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "if not os.path.exists(accuracies_norm_data_path):\n",
    "    accuracies_norm, losses_norm = get_accuracies_and_losses(normalized_models)\n",
    "\n",
    "    with open(accuracies_norm_data_path, 'w') as json_file:\n",
    "        json.dump(accuracies_norm, json_file, indent=4)\n",
    "    with open(losses_norm_data_path, 'w') as json_file:\n",
    "        json.dump(losses_norm, json_file, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "with open(accuracies_norm_data_path, 'r') as losses_file:\n",
    "    accuracies_norm = json.load(losses_file)\n",
    "with open(losses_norm_data_path, 'r') as losses_file:\n",
    "    losses_norm = json.load(losses_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracies_path = os.path.join(root, 'accuracies_norm.pdf')\n",
    "\n",
    "plot_bar_from_dict(accuracies_norm, 'Model Accuracies', 'Name', 'Accuracy', accuracies_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses_path = os.path.join(root, 'losses_norm.pdf')\n",
    "\n",
    "plot_bar_from_dict(losses_norm, 'Model Losses', 'Name', 'Accuracy', losses_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analysis part of model testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model_categories = set(map(lambda name: '_'.join(name.split('_')[:-2]), model_names))\n",
    "grouped_models = {key: list(filter(lambda name: name.startswith(key), model_names)) for key in model_categories}\n",
    "keyed_accuracies_wo_norm = {key: [] for key in grouped_models if 'normalization' not in key}\n",
    "keyed_accuracies_norm = {key: [] for key in grouped_models if 'normalization' in key}\n",
    "keyed_losses_wo_norm = {key: [] for key in grouped_models if 'normalization' not in key}\n",
    "keyed_losses_norm = {key: [] for key in grouped_models if 'normalization' in key}\n",
    "\n",
    "\n",
    "def categorize_numbers(for_dict: dict[str, list[float]], numbers_dict: dict[str, float]) -> None:\n",
    "    for group, value in for_dict.items():\n",
    "        vals = [\n",
    "            value for key, value in numbers_dict.items()\n",
    "            if key.startswith(group)]\n",
    "\n",
    "        value.extend(vals)\n",
    "\n",
    "\n",
    "categorize_numbers(keyed_accuracies_norm, accuracies_norm)\n",
    "categorize_numbers(keyed_accuracies_wo_norm, accuracies_wo_norm)\n",
    "categorize_numbers(keyed_losses_norm, losses_norm)\n",
    "categorize_numbers(keyed_losses_wo_norm, losses_wo_norm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "accuracies_from_norm_models = pd.DataFrame(keyed_accuracies_norm)\n",
    "accuracies_from_no_norm_models = pd.DataFrame(keyed_accuracies_wo_norm)\n",
    "losses_from_norm_models = pd.DataFrame(keyed_losses_norm)\n",
    "losses_from_no_norm_models = pd.DataFrame(keyed_losses_wo_norm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "       inception_ignoring_imbalance_4_only_bottom_half_layers_trainable_with_attention_module_on_top_and_samplewise_normalization  \\\ncount                                          30.000000                                                                            \nmean                                            0.759717                                                                            \nstd                                             0.011242                                                                            \nmin                                             0.739000                                                                            \n25%                                             0.752125                                                                            \n50%                                             0.759250                                                                            \n75%                                             0.766375                                                                            \nmax                                             0.778500                                                                            \n\n       inception_ignoring_imbalance_3_whole_model_trainable_with_attention_module_on_top_and_samplewise_normalization  \\\ncount                                          30.000000                                                                \nmean                                            0.753100                                                                \nstd                                             0.018877                                                                \nmin                                             0.700500                                                                \n25%                                             0.746750                                                                \n50%                                             0.758000                                                                \n75%                                             0.765250                                                                \nmax                                             0.783000                                                                \n\n       inception_ignoring_imbalance_1_whole_model_trainable_samplewise_normalization  \\\ncount                                          30.000000                               \nmean                                            0.748417                               \nstd                                             0.016311                               \nmin                                             0.705000                               \n25%                                             0.741000                               \n50%                                             0.753250                               \n75%                                             0.760500                               \nmax                                             0.769000                               \n\n       inception_ignoring_imbalance_2_only_bottom_half_layers_trainable_samplewise_normalization  \ncount                                          30.000000                                          \nmean                                            0.752600                                          \nstd                                             0.014671                                          \nmin                                             0.714000                                          \n25%                                             0.747000                                          \n50%                                             0.754750                                          \n75%                                             0.762000                                          \nmax                                             0.782000                                          ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inception_ignoring_imbalance_4_only_bottom_half_layers_trainable_with_attention_module_on_top_and_samplewise_normalization</th>\n      <th>inception_ignoring_imbalance_3_whole_model_trainable_with_attention_module_on_top_and_samplewise_normalization</th>\n      <th>inception_ignoring_imbalance_1_whole_model_trainable_samplewise_normalization</th>\n      <th>inception_ignoring_imbalance_2_only_bottom_half_layers_trainable_samplewise_normalization</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.759717</td>\n      <td>0.753100</td>\n      <td>0.748417</td>\n      <td>0.752600</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.011242</td>\n      <td>0.018877</td>\n      <td>0.016311</td>\n      <td>0.014671</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.739000</td>\n      <td>0.700500</td>\n      <td>0.705000</td>\n      <td>0.714000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.752125</td>\n      <td>0.746750</td>\n      <td>0.741000</td>\n      <td>0.747000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.759250</td>\n      <td>0.758000</td>\n      <td>0.753250</td>\n      <td>0.754750</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.766375</td>\n      <td>0.765250</td>\n      <td>0.760500</td>\n      <td>0.762000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.778500</td>\n      <td>0.783000</td>\n      <td>0.769000</td>\n      <td>0.782000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_from_norm_models.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "       inception_ignoring_imbalance_1_whole_model_trainable  \\\ncount                                          30.000000      \nmean                                            0.774250      \nstd                                             0.016210      \nmin                                             0.733500      \n25%                                             0.769125      \n50%                                             0.776500      \n75%                                             0.784875      \nmax                                             0.801500      \n\n       inception_ignoring_imbalance_2_only_bottom_half_layers_trainable  \\\ncount                                          30.000000                  \nmean                                            0.792350                  \nstd                                             0.013289                  \nmin                                             0.762000                  \n25%                                             0.784375                  \n50%                                             0.794250                  \n75%                                             0.801750                  \nmax                                             0.813500                  \n\n       inception_ignoring_imbalance_3_whole_model_trainable_with_attention_module_on_top  \\\ncount                                          30.000000                                   \nmean                                            0.793567                                   \nstd                                             0.010632                                   \nmin                                             0.777000                                   \n25%                                             0.782750                                   \n50%                                             0.795500                                   \n75%                                             0.799750                                   \nmax                                             0.816000                                   \n\n       inception_ignoring_imbalance_4_only_bottom_half_layers_trainable_with_attention_module_on_top  \ncount                                          30.000000                                              \nmean                                            0.792917                                              \nstd                                             0.007862                                              \nmin                                             0.777500                                              \n25%                                             0.788750                                              \n50%                                             0.794250                                              \n75%                                             0.797375                                              \nmax                                             0.805000                                              ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inception_ignoring_imbalance_1_whole_model_trainable</th>\n      <th>inception_ignoring_imbalance_2_only_bottom_half_layers_trainable</th>\n      <th>inception_ignoring_imbalance_3_whole_model_trainable_with_attention_module_on_top</th>\n      <th>inception_ignoring_imbalance_4_only_bottom_half_layers_trainable_with_attention_module_on_top</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.774250</td>\n      <td>0.792350</td>\n      <td>0.793567</td>\n      <td>0.792917</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.016210</td>\n      <td>0.013289</td>\n      <td>0.010632</td>\n      <td>0.007862</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.733500</td>\n      <td>0.762000</td>\n      <td>0.777000</td>\n      <td>0.777500</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.769125</td>\n      <td>0.784375</td>\n      <td>0.782750</td>\n      <td>0.788750</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.776500</td>\n      <td>0.794250</td>\n      <td>0.795500</td>\n      <td>0.794250</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.784875</td>\n      <td>0.801750</td>\n      <td>0.799750</td>\n      <td>0.797375</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.801500</td>\n      <td>0.813500</td>\n      <td>0.816000</td>\n      <td>0.805000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_from_no_norm_models.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "       inception_ignoring_imbalance_4_only_bottom_half_layers_trainable_with_attention_module_on_top_and_samplewise_normalization  \\\ncount                                          30.000000                                                                            \nmean                                            0.673036                                                                            \nstd                                             0.026645                                                                            \nmin                                             0.629656                                                                            \n25%                                             0.650746                                                                            \n50%                                             0.670872                                                                            \n75%                                             0.694725                                                                            \nmax                                             0.722168                                                                            \n\n       inception_ignoring_imbalance_3_whole_model_trainable_with_attention_module_on_top_and_samplewise_normalization  \\\ncount                                          30.000000                                                                \nmean                                            0.691220                                                                \nstd                                             0.048443                                                                \nmin                                             0.641208                                                                \n25%                                             0.659710                                                                \n50%                                             0.675271                                                                \n75%                                             0.706006                                                                \nmax                                             0.837553                                                                \n\n       inception_ignoring_imbalance_1_whole_model_trainable_samplewise_normalization  \\\ncount                                          30.000000                               \nmean                                            0.709701                               \nstd                                             0.052602                               \nmin                                             0.636466                               \n25%                                             0.674715                               \n50%                                             0.692928                               \n75%                                             0.743005                               \nmax                                             0.825080                               \n\n       inception_ignoring_imbalance_2_only_bottom_half_layers_trainable_samplewise_normalization  \ncount                                          30.000000                                          \nmean                                            0.703292                                          \nstd                                             0.044011                                          \nmin                                             0.652724                                          \n25%                                             0.676151                                          \n50%                                             0.699332                                          \n75%                                             0.722880                                          \nmax                                             0.869296                                          ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inception_ignoring_imbalance_4_only_bottom_half_layers_trainable_with_attention_module_on_top_and_samplewise_normalization</th>\n      <th>inception_ignoring_imbalance_3_whole_model_trainable_with_attention_module_on_top_and_samplewise_normalization</th>\n      <th>inception_ignoring_imbalance_1_whole_model_trainable_samplewise_normalization</th>\n      <th>inception_ignoring_imbalance_2_only_bottom_half_layers_trainable_samplewise_normalization</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.673036</td>\n      <td>0.691220</td>\n      <td>0.709701</td>\n      <td>0.703292</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.026645</td>\n      <td>0.048443</td>\n      <td>0.052602</td>\n      <td>0.044011</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.629656</td>\n      <td>0.641208</td>\n      <td>0.636466</td>\n      <td>0.652724</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.650746</td>\n      <td>0.659710</td>\n      <td>0.674715</td>\n      <td>0.676151</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.670872</td>\n      <td>0.675271</td>\n      <td>0.692928</td>\n      <td>0.699332</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.694725</td>\n      <td>0.706006</td>\n      <td>0.743005</td>\n      <td>0.722880</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.722168</td>\n      <td>0.837553</td>\n      <td>0.825080</td>\n      <td>0.869296</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_from_norm_models.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "       inception_ignoring_imbalance_1_whole_model_trainable  \\\ncount                                          30.000000      \nmean                                            0.628121      \nstd                                             0.046395      \nmin                                             0.572206      \n25%                                             0.596247      \n50%                                             0.621229      \n75%                                             0.644392      \nmax                                             0.747070      \n\n       inception_ignoring_imbalance_2_only_bottom_half_layers_trainable  \\\ncount                                          30.000000                  \nmean                                            0.596638                  \nstd                                             0.033383                  \nmin                                             0.541605                  \n25%                                             0.575664                  \n50%                                             0.590225                  \n75%                                             0.625841                  \nmax                                             0.668844                  \n\n       inception_ignoring_imbalance_3_whole_model_trainable_with_attention_module_on_top  \\\ncount                                          30.000000                                   \nmean                                            0.587635                                   \nstd                                             0.022151                                   \nmin                                             0.538928                                   \n25%                                             0.571949                                   \n50%                                             0.584879                                   \n75%                                             0.601979                                   \nmax                                             0.633576                                   \n\n       inception_ignoring_imbalance_4_only_bottom_half_layers_trainable_with_attention_module_on_top  \ncount                                          30.000000                                              \nmean                                            0.582946                                              \nstd                                             0.018216                                              \nmin                                             0.552645                                              \n25%                                             0.572053                                              \n50%                                             0.578076                                              \n75%                                             0.592483                                              \nmax                                             0.641276                                              ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>inception_ignoring_imbalance_1_whole_model_trainable</th>\n      <th>inception_ignoring_imbalance_2_only_bottom_half_layers_trainable</th>\n      <th>inception_ignoring_imbalance_3_whole_model_trainable_with_attention_module_on_top</th>\n      <th>inception_ignoring_imbalance_4_only_bottom_half_layers_trainable_with_attention_module_on_top</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.628121</td>\n      <td>0.596638</td>\n      <td>0.587635</td>\n      <td>0.582946</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.046395</td>\n      <td>0.033383</td>\n      <td>0.022151</td>\n      <td>0.018216</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.572206</td>\n      <td>0.541605</td>\n      <td>0.538928</td>\n      <td>0.552645</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.596247</td>\n      <td>0.575664</td>\n      <td>0.571949</td>\n      <td>0.572053</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.621229</td>\n      <td>0.590225</td>\n      <td>0.584879</td>\n      <td>0.578076</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.644392</td>\n      <td>0.625841</td>\n      <td>0.601979</td>\n      <td>0.592483</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.747070</td>\n      <td>0.668844</td>\n      <td>0.633576</td>\n      <td>0.641276</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_from_no_norm_models.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "ALPHA = .05\n",
    "anova_testable_groups = []\n",
    "kruskal_walis_testable_groups = []\n",
    "\n",
    "\n",
    "def assign_models_to_groups(models: pd.DataFrame) -> None:\n",
    "    for col in models.columns:\n",
    "        _, p_value = shapiro(models[col])\n",
    "\n",
    "        if p_value >= ALPHA:\n",
    "            anova_testable_groups.append(col)\n",
    "        else:\n",
    "            kruskal_walis_testable_groups.append(col)\n",
    "\n",
    "\n",
    "assign_models_to_groups(accuracies_from_norm_models)\n",
    "assign_models_to_groups(accuracies_from_no_norm_models)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA p-value: 4.064446737409379e-37\n",
      "Kruskal-Wallis p-value: 0.17359764347681522\n"
     ]
    }
   ],
   "source": [
    "anova_values = []\n",
    "kruskal_values = []\n",
    "anova_cols = []\n",
    "\n",
    "for col in anova_testable_groups:\n",
    "    if col in accuracies_from_norm_models:\n",
    "        anova_values.append(accuracies_from_norm_models[col].tolist())\n",
    "        anova_cols.append(col)\n",
    "    if col in accuracies_from_no_norm_models:\n",
    "        anova_values.append(accuracies_from_no_norm_models[col].tolist())\n",
    "        anova_cols.append(col)\n",
    "\n",
    "for col in kruskal_walis_testable_groups:\n",
    "    if col in accuracies_from_norm_models:\n",
    "        kruskal_values.append(accuracies_from_norm_models[col].tolist())\n",
    "    if col in accuracies_from_no_norm_models:\n",
    "        kruskal_values.append(accuracies_from_no_norm_models[col].tolist())\n",
    "\n",
    "\n",
    "f_stat_anova, p_value_anova = f_oneway(*anova_values)\n",
    "h_stat_kruskal, p_value_kruskal = kruskal(*kruskal_values)\n",
    "\n",
    "print(f'ANOVA p-value: {p_value_anova}')\n",
    "print(f'Kruskal-Wallis p-value: {p_value_kruskal}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ANOVA p-value is extremely small, practically zero, which strongly indicates that there are significant differences between the means of the groups tested (those groups which passed the normality test). I reject the null hypothesis of equal means. Given this result, it's warranted to proceed to post-hoc analysis (like Tukey's HSD) to find out which specific groups have significantly different means.\n",
    "\n",
    "Kruskal-Wallis p-value is relatively large (greater than common thresholds like 0.05 or 0.01), which suggests that I fail to reject the null hypothesis for the Kruskal-Wallis test. This indicates that there isn't a statistically significant difference between the median ranks of the groups tested (those groups which failed the normality test)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "tukey_vals = list(itertools.chain(*anova_values))\n",
    "tukey_cols = []\n",
    "idx = 0\n",
    "\n",
    "for col in anova_values:\n",
    "    n_repeat = len(col)\n",
    "    group = [anova_cols[idx]] * n_repeat\n",
    "    idx += 1\n",
    "\n",
    "    tukey_cols.extend(group)\n",
    "\n",
    "mc = MultiComparison(tukey_vals, tukey_cols)\n",
    "result = str(mc.tukeyhsd())\n",
    "\n",
    "with open(os.path.join('..', '..', 'debug_data', 'tukeyhsd.test'), 'w') as test_file:\n",
    "    test_file.write(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
